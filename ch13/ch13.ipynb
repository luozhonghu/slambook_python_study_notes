{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这章主要讲的是slam 的3D重建，就是通过 深度图+单目 或者其他形式的组合获得对应3D图\n",
    "\n",
    "octomap_mapping.cpp 这个脚本主要是用来创建一个 3D 环境的八叉树地图（Octomap）。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image 1\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m在当前单元格或上一个单元格中执行代码时 Kernel 崩溃。\n",
      "\u001b[1;31m请查看单元格中的代码，以确定故障的可能原因。\n",
      "\u001b[1;31m单击<a href='https://aka.ms/vscodeJupyterKernelCrash'>此处</a>了解详细信息。\n",
      "\u001b[1;31m有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import cv2\n",
    "import os\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "def read_pose(file_path):\n",
    "    poses = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            data = list(map(float, line.strip().split()))\n",
    "            T = np.eye(4)\n",
    "            T[:3, 3] = data[:3]\n",
    "            T[:3, :3] = R.from_quat(data[3:]).as_matrix()\n",
    "            poses.append(T)\n",
    "    return poses\n",
    "\n",
    "def create_point_cloud(color_img, depth_img, K, depth_scale):\n",
    "    cx, cy = K[0, 2], K[1, 2]\n",
    "    fx, fy = K[0, 0], K[1, 1]\n",
    "    \n",
    "    points = []\n",
    "    colors = []\n",
    "    \n",
    "    for v in range(depth_img.shape[0]):\n",
    "        for u in range(depth_img.shape[1]):\n",
    "            d = depth_img[v, u]\n",
    "            if d == 0 or d >= 7000:\n",
    "                continue\n",
    "            \n",
    "            z = d / depth_scale\n",
    "            x = (u - cx) * z / fx\n",
    "            y = (v - cy) * z / fy\n",
    "            \n",
    "            points.append([x, y, z])\n",
    "            colors.append(color_img[v, u] / 255.0)\n",
    "    \n",
    "    return np.array(points), np.array(colors)\n",
    "\n",
    "def main():\n",
    "    # Camera parameters\n",
    "    cx, cy = 325.5, 253.5\n",
    "    fx, fy = 518.0, 519.0\n",
    "    depth_scale = 1000.0\n",
    "    K = np.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]])\n",
    "\n",
    "    # Read poses\n",
    "    poses = read_pose('./dense_RGBD/data/pose.txt')\n",
    "\n",
    "    # Create octree\n",
    "    octree = o3d.geometry.Octree(max_depth=16)\n",
    "\n",
    "    for i in range(5):\n",
    "        print(f\"Processing image {i+1}\")\n",
    "        color_img = cv2.imread(f'./dense_RGBD/data/color/{i+1}.png')\n",
    "        depth_img = cv2.imread(f'./dense_RGBD/data/depth/{i+1}.pgm', -1)\n",
    "        \n",
    "        points, colors = create_point_cloud(color_img, depth_img, K, depth_scale)\n",
    "        \n",
    "        # Transform points to world coordinate\n",
    "        points = (poses[i][:3, :3] @ points.T + poses[i][:3, 3:]).T\n",
    "        \n",
    "        pcd = o3d.geometry.PointCloud()\n",
    "        pcd.points = o3d.utility.Vector3dVector(points)\n",
    "        pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "        \n",
    "        # Insert point cloud to octree\n",
    "        octree.convert_from_point_cloud(pcd, size_expand=0.01)\n",
    "\n",
    "    # Save octree\n",
    "    o3d.io.write_octree(\"octomap.octree\", octree)\n",
    "    print(\"Octree saved as octomap.octree\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bytedance/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m在当前单元格或上一个单元格中执行代码时 Kernel 崩溃。\n",
      "\u001b[1;31m请查看单元格中的代码，以确定故障的可能原因。\n",
      "\u001b[1;31m单击<a href='https://aka.ms/vscodeJupyterKernelCrash'>此处</a>了解详细信息。\n",
      "\u001b[1;31m有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import cv2\n",
    "import os\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "from tqdm import tqdm\n",
    "\n",
    "def read_pose(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            data = list(map(float, line.strip().split()))\n",
    "            T = np.eye(4)\n",
    "            T[:3, 3] = data[:3]\n",
    "            T[:3, :3] = R.from_quat(data[3:]).as_matrix()\n",
    "            yield T\n",
    "\n",
    "def create_point_cloud(color_img, depth_img, K, depth_scale):\n",
    "    cx, cy = K[0, 2], K[1, 2]\n",
    "    fx, fy = K[0, 0], K[1, 1]\n",
    "    \n",
    "    points = []\n",
    "    colors = []\n",
    "    \n",
    "    for v in range(0, depth_img.shape[0], 2):  # 降采样\n",
    "        for u in range(0, depth_img.shape[1], 2):\n",
    "            d = depth_img[v, u]\n",
    "            if d == 0 or d >= 7000:\n",
    "                continue\n",
    "            \n",
    "            z = d / depth_scale\n",
    "            x = (u - cx) * z / fx\n",
    "            y = (v - cy) * z / fy\n",
    "            \n",
    "            points.append([x, y, z])\n",
    "            colors.append(color_img[v, u] / 255.0)\n",
    "    \n",
    "    return np.array(points), np.array(colors)\n",
    "\n",
    "def process_image(i, pose, K, depth_scale):\n",
    "    print(f\"Processing image {i+1}\")\n",
    "    color_img = cv2.imread(f'./dense_RGBD/data/color/{i+1}.png')\n",
    "    depth_img = cv2.imread(f'./dense_RGBD/data/depth/{i+1}.pgm', -1)\n",
    "    \n",
    "    points, colors = create_point_cloud(color_img, depth_img, K, depth_scale)\n",
    "    \n",
    "    # Transform points to world coordinate\n",
    "    points = (pose[:3, :3] @ points.T + pose[:3, 3:]).T\n",
    "    \n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(points)\n",
    "    pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "    \n",
    "    return pcd\n",
    "\n",
    "def main():\n",
    "    # Camera parameters\n",
    "    cx, cy = 325.5, 253.5\n",
    "    fx, fy = 518.0, 519.0\n",
    "    depth_scale = 1000.0\n",
    "    K = np.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]])\n",
    "\n",
    "    # Read poses\n",
    "    poses = list(read_pose('./dense_RGBD/data/pose.txt'))\n",
    "\n",
    "    # Create octree\n",
    "    octree = o3d.geometry.Octree(max_depth=16)\n",
    "\n",
    "    # Process images and update octree\n",
    "    for i, pose in tqdm(enumerate(poses[:5]), total=5):\n",
    "        pcd = process_image(i, pose, K, depth_scale)\n",
    "        octree.convert_from_point_cloud(pcd, size_expand=0.01)\n",
    "\n",
    "    # Save octree\n",
    "    o3d.io.write_octree(\"octomap.octree\", octree)\n",
    "    print(\"Octree saved as octomap.octree\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 垃圾 mac ，一点都跑不了额"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bytedance/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image 1\n",
      "Processing image 2\n",
      "Processing image 3\n",
      "Processing image 4\n",
      "Processing image 5\n",
      "Point cloud has 895249 points before downsampling\n",
      "Point cloud has 448493 points after downsampling\n",
      "Point cloud saved as map.pcd\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import open3d as o3d\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "import os\n",
    "\n",
    "def read_pose(file_path):\n",
    "    poses = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            data = list(map(float, line.strip().split()))\n",
    "            T = np.eye(4)\n",
    "            T[:3, 3] = data[:3]\n",
    "            T[:3, :3] = R.from_quat(data[3:]).as_matrix()\n",
    "            poses.append(T)\n",
    "    return poses\n",
    "\n",
    "def create_point_cloud(color_img, depth_img, K, depth_scale, T):\n",
    "    cx, cy = K[0, 2], K[1, 2]\n",
    "    fx, fy = K[0, 0], K[1, 1]\n",
    "    \n",
    "    points = []\n",
    "    colors = []\n",
    "    \n",
    "    for v in range(depth_img.shape[0]):\n",
    "        for u in range(depth_img.shape[1]):\n",
    "            d = depth_img[v, u]\n",
    "            if d == 0 or d >= 7000:\n",
    "                continue\n",
    "            \n",
    "            z = d / depth_scale\n",
    "            x = (u - cx) * z / fx\n",
    "            y = (v - cy) * z / fy\n",
    "            \n",
    "            point = np.array([x, y, z, 1])\n",
    "            point_world = T @ point\n",
    "            \n",
    "            points.append(point_world[:3])\n",
    "            colors.append(color_img[v, u][::-1] / 255.0)  # BGR to RGB\n",
    "    \n",
    "    return np.array(points), np.array(colors)\n",
    "\n",
    "def main():\n",
    "    # Camera parameters\n",
    "    cx, cy = 325.5, 253.5\n",
    "    fx, fy = 518.0, 519.0\n",
    "    depth_scale = 1000.0\n",
    "    K = np.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]])\n",
    "\n",
    "    # Read poses\n",
    "    poses = read_pose('./dense_RGBD/data/pose.txt')\n",
    "\n",
    "    # Create point cloud\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "\n",
    "    for i in range(5):\n",
    "        print(f\"Processing image {i+1}\")\n",
    "        color_img = cv2.imread(f'./dense_RGBD/data/color/{i+1}.png')\n",
    "        depth_img = cv2.imread(f'./dense_RGBD/data/depth/{i+1}.pgm', -1)\n",
    "        \n",
    "        points, colors = create_point_cloud(color_img, depth_img, K, depth_scale, poses[i])\n",
    "        \n",
    "        current_pcd = o3d.geometry.PointCloud()\n",
    "        current_pcd.points = o3d.utility.Vector3dVector(points)\n",
    "        current_pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "        \n",
    "        # Statistical outlier removal\n",
    "        current_pcd, _ = current_pcd.remove_statistical_outlier(nb_neighbors=50, std_ratio=1.0)\n",
    "        \n",
    "        pcd += current_pcd\n",
    "\n",
    "    print(f\"Point cloud has {len(pcd.points)} points before downsampling\")\n",
    "\n",
    "    # Voxel downsampling\n",
    "    pcd = pcd.voxel_down_sample(voxel_size=0.01)\n",
    "\n",
    "    print(f\"Point cloud has {len(pcd.points)} points after downsampling\")\n",
    "\n",
    "    # Save point cloud\n",
    "    o3d.io.write_point_cloud(\"map.pcd\", pcd)\n",
    "    print(\"Point cloud saved as map.pcd\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "下面这个是深度+单目的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading image files failed!\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "-1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m -1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bytedance/Library/Python/3.9/lib/python/site-packages/IPython/core/interactiveshell.py:3558: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "# 参数\n",
    "BOARDER = 20\n",
    "WIDTH = 640\n",
    "HEIGHT = 480\n",
    "FX = 481.2\n",
    "FY = -480.0\n",
    "CX = 319.5\n",
    "CY = 239.5\n",
    "NCC_WINDOW_SIZE = 2\n",
    "NCC_AREA = (2 * NCC_WINDOW_SIZE + 1) * (2 * NCC_WINDOW_SIZE + 1)\n",
    "MIN_COV = 0.1\n",
    "MAX_COV = 10\n",
    "\n",
    "\n",
    "def read_dataset_files(path):\n",
    "    color_image_files = []\n",
    "    poses = []\n",
    "    try:\n",
    "        with open(f\"{path}/first_200_frames_traj_over_table_input_sequence.txt\", 'r') as fin:\n",
    "            for line in fin:\n",
    "                data = line.strip().split()  #这快有问题呀\n",
    "                image = data[0]\n",
    "                pose_data = [float(x) for x in data[1:]]\n",
    "                color_image_files.append(f\"{path}/color/{image}\")\n",
    "                r = R.from_quat([pose_data[3], pose_data[4], pose_data[5], pose_data[6]])\n",
    "                t = np.array(pose_data[:3])\n",
    "                T = np.eye(4)\n",
    "                T[:3, :3] = r.as_matrix()\n",
    "                T[:3, 3] = t\n",
    "                poses.append(T)\n",
    "    except FileNotFoundError:\n",
    "        return False, [], []\n",
    "    return True, color_image_files, poses\n",
    "\n",
    "\n",
    "def px2cam(px):\n",
    "    return np.array([(px[0] - CX) / FX, (px[1] - CY) / FY, 1])\n",
    "\n",
    "\n",
    "def cam2px(p_cam):\n",
    "    return np.array([p_cam[0] * FX / p_cam[2] + CX, p_cam[1] * FY / p_cam[2] + CY])\n",
    "\n",
    "\n",
    "def inside(pt):\n",
    "    return (pt[0] >= BOARDER + NCC_WINDOW_SIZE and pt[1] >= BOARDER + NCC_WINDOW_SIZE and\n",
    "            pt[0] + BOARDER + NCC_WINDOW_SIZE < WIDTH and pt[1] + BOARDER + NCC_WINDOW_SIZE <= HEIGHT)\n",
    "\n",
    "\n",
    "def get_bilinear_interpolated_value(img, pt):\n",
    "    x = pt[0]\n",
    "    y = pt[1]\n",
    "    x1 = int(x)\n",
    "    y1 = int(y)\n",
    "    x2 = x1 + 1\n",
    "    y2 = y1 + 1\n",
    "    xx = x - x1\n",
    "    yy = y - y1\n",
    "    if x2 >= img.shape[1]:\n",
    "        x2 = img.shape[1] - 1\n",
    "    if y2 >= img.shape[0]:\n",
    "        y2 = img.shape[0] - 1\n",
    "    return ((1 - xx) * (1 - yy) * img[y1, x1] +\n",
    "            xx * (1 - yy) * img[y1, x2] +\n",
    "            (1 - xx) * yy * img[y2, x1] +\n",
    "            xx * yy * img[y2, x2]) / 255.0\n",
    "\n",
    "\n",
    "def NCC(ref, curr, pt_ref, pt_curr):\n",
    "    mean_ref = 0\n",
    "    mean_curr = 0\n",
    "    values_ref = []\n",
    "    values_curr = []\n",
    "    for x in range(-NCC_WINDOW_SIZE, NCC_WINDOW_SIZE + 1):\n",
    "        for y in range(-NCC_WINDOW_SIZE, NCC_WINDOW_SIZE + 1):\n",
    "            value_ref = ref[int(pt_ref[1] + y), int(pt_ref[0] + x)] / 255.0\n",
    "            mean_ref += value_ref\n",
    "            value_curr = get_bilinear_interpolated_value(curr, pt_curr + np.array([x, y]))\n",
    "            mean_curr += value_curr\n",
    "            values_ref.append(value_ref)\n",
    "            values_curr.append(value_curr)\n",
    "    mean_ref /= NCC_AREA\n",
    "    mean_curr /= NCC_AREA\n",
    "    numerator = 0\n",
    "    demoniator1 = 0\n",
    "    demoniator2 = 0\n",
    "    for i in range(len(values_ref)):\n",
    "        n = (values_ref[i] - mean_ref) * (values_curr[i] - mean_curr)\n",
    "        numerator += n\n",
    "        demoniator1 += (values_ref[i] - mean_ref) ** 2\n",
    "        demoniator2 += (values_curr[i] - mean_curr) ** 2\n",
    "    return numerator / np.sqrt(demoniator1 * demoniator2 + 1e-10)\n",
    "\n",
    "\n",
    "def epipolar_search(ref, curr, T_C_R, pt_ref, depth_mu, depth_cov):\n",
    "    f_ref = px2cam(pt_ref)\n",
    "    f_ref = f_ref / np.linalg.norm(f_ref)\n",
    "    P_ref = f_ref * depth_mu\n",
    "    px_mean_curr = cam2px(T_C_R[:3, :3] @ P_ref + T_C_R[:3, 3])\n",
    "    d_min = max(depth_mu - 3 * depth_cov, 0.1)\n",
    "    d_max = depth_mu + 3 * depth_cov\n",
    "    px_min_curr = cam2px(T_C_R[:3, :3] @ (f_ref * d_min) + T_C_R[:3, 3])\n",
    "    px_max_curr = cam2px(T_C_R[:3, :3] @ (f_ref * d_max) + T_C_R[:3, 3])\n",
    "    epipolar_line = px_max_curr - px_min_curr\n",
    "    epipolar_direction = epipolar_line / np.linalg.norm(epipolar_line)\n",
    "    half_length = min(0.5 * np.linalg.norm(epipolar_line), 100)\n",
    "    best_ncc = -1.0\n",
    "    best_px_curr = None\n",
    "    for l in np.arange(-half_length, half_length + 0.7, 0.7):\n",
    "        px_curr = px_mean_curr + l * epipolar_direction\n",
    "        if not inside(px_curr):\n",
    "            continue\n",
    "        ncc = NCC(ref, curr, pt_ref, px_curr)\n",
    "        if ncc > best_ncc:\n",
    "            best_ncc = ncc\n",
    "            best_px_curr = px_curr\n",
    "    if best_ncc < 0.85:\n",
    "        return False, None\n",
    "    return True, best_px_curr\n",
    "\n",
    "\n",
    "def update_depth_filter(pt_ref, pt_curr, T_C_R, depth, depth_cov):\n",
    "    T_R_C = np.linalg.inv(T_C_R)\n",
    "    f_ref = px2cam(pt_ref)\n",
    "    f_ref = f_ref / np.linalg.norm(f_ref)\n",
    "    f_curr = px2cam(pt_curr)\n",
    "    f_curr = f_curr / np.linalg.norm(f_curr)\n",
    "    t = T_R_C[:3, 3]\n",
    "    f2 = T_R_C[:3, :3] @ f_curr\n",
    "    b = np.array([np.dot(f_ref, t), np.dot(f2, t)])\n",
    "    A = np.array([[np.dot(f_ref, f_ref), -np.dot(f_ref, f2)],\n",
    "                  [np.dot(f2, f_ref), -np.dot(f2, f2)]])\n",
    "    d = np.linalg.det(A)\n",
    "    lambdavec = np.linalg.inv(A) @ b\n",
    "    xm = lambdavec[0] * f_ref\n",
    "    xn = t + lambdavec[1] * f2\n",
    "    d_esti = (xm + xn) / 2.0\n",
    "    depth_estimation = np.linalg.norm(d_esti)\n",
    "    p = f_ref * depth_estimation\n",
    "    a = p - t\n",
    "    t_norm = np.linalg.norm(t)\n",
    "    a_norm = np.linalg.norm(a)\n",
    "    alpha = np.arccos(np.dot(f_ref, t) / t_norm)\n",
    "    beta = np.arccos(-np.dot(a, t) / (a_norm * t_norm))\n",
    "    beta_prime = beta + np.arctan(1 / FX)\n",
    "    gamma = np.pi - alpha - beta_prime\n",
    "    p_prime = t_norm * np.sin(beta_prime) / np.sin(gamma)\n",
    "    d_cov_est = p_prime - depth_estimation\n",
    "    d_cov2 = d_cov_est ** 2\n",
    "    mu = depth[int(pt_ref[1]), int(pt_ref[0])]\n",
    "    sigma2 = depth_cov[int(pt_ref[1]), int(pt_ref[0])]\n",
    "    mu_fuse = (d_cov2 * mu + sigma2 * depth_estimation) / (sigma2 + d_cov2)\n",
    "    sigma_fuse2 = (sigma2 * d_cov2) / (sigma2 + d_cov2)\n",
    "    depth[int(pt_ref[1]), int(pt_ref[0])] = mu_fuse\n",
    "    depth_cov[int(pt_ref[1]), int(pt_ref[0])] = sigma_fuse2\n",
    "    return True\n",
    "\n",
    "\n",
    "def update(ref, curr, T_C_R, depth, depth_cov):\n",
    "    for x in range(BOARDER, WIDTH - BOARDER):\n",
    "        for y in range(BOARDER, HEIGHT - BOARDER):\n",
    "            if depth_cov[y, x] < MIN_COV or depth_cov[y, x] > MAX_COV:\n",
    "                continue\n",
    "            ret, pt_curr = epipolar_search(ref, curr, T_C_R, np.array([x, y]), depth[y, x], np.sqrt(depth_cov[y, x]))\n",
    "            if ret:\n",
    "                update_depth_filter(np.array([x, y]), pt_curr, T_C_R, depth, depth_cov)\n",
    "    return True\n",
    "\n",
    "\n",
    "def plot_depth(depth):\n",
    "    cv2.imshow(\"depth\", depth * 0.4)\n",
    "    cv2.waitKey(1)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import sys\n",
    "    if len(sys.argv) != 2:\n",
    "        print(\"Usage: dense_mapping path_to_test_dataset\")\n",
    "        sys.exit(-1)\n",
    "    path = sys.argv[1]\n",
    "    ret, color_image_files, poses_TWC = read_dataset_files(path)\n",
    "    if not ret:\n",
    "        print(\"Reading image files failed!\")\n",
    "        sys.exit(-1)\n",
    "    print(f\"read total {len(color_image_files)} files.\")\n",
    "    ref = cv2.imread(color_image_files[0], 0)\n",
    "    pose_ref_TWC = poses_TWC[0]\n",
    "    init_depth = 3.0\n",
    "    init_cov2 = 3.0\n",
    "    depth = np.full((HEIGHT, WIDTH), init_depth, dtype=np.float64)\n",
    "    depth_cov = np.full((HEIGHT, WIDTH), init_cov2, dtype=np.float64)\n",
    "    for index in range(1, len(color_image_files)):\n",
    "        print(f\"*** loop {index} ***\")\n",
    "        curr = cv2.imread(color_image_files[index], 0)\n",
    "        if curr is None:\n",
    "            continue\n",
    "        pose_curr_TWC = poses_TWC[index]\n",
    "        pose_T_C_R = np.linalg.inv(pose_curr_TWC) @ pose_ref_TWC\n",
    "        update(ref, curr, pose_T_C_R, depth, depth_cov)\n",
    "        plot_depth(depth)\n",
    "        cv2.imshow(\"image\", curr)\n",
    "        cv2.waitKey(1)\n",
    "    print(\"estimation returns, saving depth map ...\")\n",
    "    cv2.imwrite(\"depth.png\", depth)\n",
    "    print(\"done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
